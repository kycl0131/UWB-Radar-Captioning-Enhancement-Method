Epoch 1/30:   0%|                                                                                                                                                                             | 0/574 [00:00<?, ?it/s]
Traceback (most recent call last):
  File "/home/yunkwan/project/radarclip/Radarcap_main.py", line 218, in <module>
    main(args.train_1024, args.train_768, args.epochs, args.batch_size)
  File "/home/yunkwan/project/radarclip/Radarcap_main.py", line 199, in main
    train_model(encoder_search_resnet1D_1024, retrieval_model, train_loader, val_loader, criterion, optimizer, prepro_image_features_1024, num_epochs=num_epochs)
  File "/home/yunkwan/project/radarclip/Radarcap_main.py", line 137, in train_model
    images_features = prepro_image_fn(images, retrieval_model, device, batch_size=32)
  File "/home/yunkwan/project/radarclip/Radarcap_main.py", line 115, in prepro_image_features_1024
    features = retrieval_model.encode_image(batch_images)
  File "/home/yunkwan/anaconda3/envs/smallcap/lib/python3.9/site-packages/clip/model.py", line 341, in encode_image
    return self.visual(image.type(self.dtype))
  File "/home/yunkwan/anaconda3/envs/smallcap/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/yunkwan/anaconda3/envs/smallcap/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1541, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/yunkwan/anaconda3/envs/smallcap/lib/python3.9/site-packages/clip/model.py", line 228, in forward
    x = x + self.positional_embedding.to(x.dtype)
RuntimeError: The size of tensor a (197) must match the size of tensor b (50) at non-singleton dimension 1