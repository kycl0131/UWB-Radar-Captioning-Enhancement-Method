Epoch 1/100: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 94/94 [01:26<00:00,  1.08it/s, loss=0.106]
Epoch 1/100, Train Loss: 0.1058, Train_acc: 0.9648, Val Loss: 4.9861 , Val_acc: 0.2078
Epoch 2/100: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 94/94 [01:26<00:00,  1.09it/s, loss=6.91e-5]
Epoch 2/100, Train Loss: 0.0001, Train_acc: 1.0000, Val Loss: 3.3454 , Val_acc: 0.1395
Epoch 3/100: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 94/94 [01:34<00:00,  1.00s/it, loss=3.65e-5]
Epoch 3/100, Train Loss: 0.0000, Train_acc: 1.0000, Val Loss: 3.0926 , Val_acc: 0.1883
Epoch 4/100: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 94/94 [01:25<00:00,  1.10it/s, loss=2.67e-5]
Epoch 4/100, Train Loss: 0.0000, Train_acc: 1.0000, Val Loss: 2.8507 , Val_acc: 0.2260
Epoch 5/100: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 94/94 [01:30<00:00,  1.04it/s, loss=1.99e-5]
Epoch 5/100, Train Loss: 0.0000, Train_acc: 1.0000, Val Loss: 3.2192 , Val_acc: 0.1345
Epoch 6/100: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 94/94 [01:33<00:00,  1.01it/s, loss=1.58e-5]
Epoch 6/100, Train Loss: 0.0000, Train_acc: 1.0000, Val Loss: 3.1074 , Val_acc: 0.1590
Epoch 7/100: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 94/94 [01:27<00:00,  1.08it/s, loss=1.43e-5]
Epoch 7/100, Train Loss: 0.0000, Train_acc: 1.0000, Val Loss: 3.2025 , Val_acc: 0.0837
Epoch 8/100: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 94/94 [01:26<00:00,  1.08it/s, loss=1.31e-5]
Epoch 8/100, Train Loss: 0.0000, Train_acc: 1.0000, Val Loss: 2.9281 , Val_acc: 0.1117
Epoch 9/100: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 94/94 [01:28<00:00,  1.07it/s, loss=1.15e-5]
Epoch 9/100, Train Loss: 0.0000, Train_acc: 1.0000, Val Loss: 3.1269 , Val_acc: 0.1748
Epoch 10/100: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 94/94 [01:23<00:00,  1.13it/s, loss=9.76e-6]
Epoch 10/100, Train Loss: 0.0000, Train_acc: 1.0000, Val Loss: 3.0000 , Val_acc: 0.1827
Epoch 11/100: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 94/94 [01:27<00:00,  1.07it/s, loss=1.01e-5]
Epoch 11/100, Train Loss: 0.0000, Train_acc: 1.0000, Val Loss: 2.7685 , Val_acc: 0.1542
Epoch 12/100:  33%|████████████████████████████████████████████████████████▍                                                                                                                  | 31/94 [00:28<00:58,  1.09it/s, loss=8.47e-6]
Traceback (most recent call last):
  File "/home/yunkwan/project/radarclip/Radarcap_main_cl.py", line 359, in <module>
    main(args.train_3, args.epochs, args.batch_size, args.test_mode)
  File "/home/yunkwan/project/radarclip/Radarcap_main_cl.py", line 346, in main
    train_model(encoder_search_resnet1D_3, train_loader, val_loader, criterion, optimizer,warmup_scheduler,cosine_scheduler, num_epochs=num_epochs,filter = LearnableLogFilter_3)
  File "/home/yunkwan/project/radarclip/Radarcap_main_cl.py", line 158, in train_model
    for images, radars,_,_,labels in train_loader_tqdm:
  File "/home/yunkwan/anaconda3/envs/smallcap/lib/python3.9/site-packages/tqdm/std.py", line 1195, in __iter__
    for obj in iterable:
  File "/home/yunkwan/anaconda3/envs/smallcap/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 631, in __next__
    data = self._next_data()
  File "/home/yunkwan/anaconda3/envs/smallcap/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 675, in _next_data
    data = self._dataset_fetcher.fetch(index)  # may raise StopIteration
  File "/home/yunkwan/anaconda3/envs/smallcap/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py", line 51, in fetch
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/home/yunkwan/anaconda3/envs/smallcap/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py", line 51, in <listcomp>
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/home/yunkwan/project/radarclip/dataload.py", line 113, in __getitem__
    image = self.transform(image)
  File "/home/yunkwan/anaconda3/envs/smallcap/lib/python3.9/site-packages/torchvision/transforms/transforms.py", line 95, in __call__
    img = t(img)
  File "/home/yunkwan/anaconda3/envs/smallcap/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/yunkwan/anaconda3/envs/smallcap/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1541, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/yunkwan/anaconda3/envs/smallcap/lib/python3.9/site-packages/torchvision/transforms/transforms.py", line 354, in forward
    return F.resize(img, self.size, self.interpolation, self.max_size, self.antialias)
  File "/home/yunkwan/anaconda3/envs/smallcap/lib/python3.9/site-packages/torchvision/transforms/functional.py", line 470, in resize
    return F_t.resize(img, size=output_size, interpolation=interpolation.value, antialias=antialias)
  File "/home/yunkwan/anaconda3/envs/smallcap/lib/python3.9/site-packages/torchvision/transforms/_functional_tensor.py", line 465, in resize
    img = interpolate(img, size=size, mode=interpolation, align_corners=align_corners, antialias=antialias)
  File "/home/yunkwan/anaconda3/envs/smallcap/lib/python3.9/site-packages/torch/nn/functional.py", line 4055, in interpolate
    return torch._C._nn._upsample_bilinear2d_aa(input, output_size, align_corners, scale_factors)
KeyboardInterrupt
