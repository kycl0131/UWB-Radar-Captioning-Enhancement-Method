Epoch 1/200: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 94/94 [01:50<00:00,  1.17s/it, loss=0.109]
Epoch 1/200, Train Loss: 0.1091, Train_acc: 0.4328, Val Loss: 1.1000, Val_acc: 0.3333
Epoch 2/200: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 94/94 [01:51<00:00,  1.19s/it, loss=0.102]
Epoch 2/200, Train Loss: 0.1021, Train_acc: 0.5992, Val Loss: 0.9847, Val_acc: 0.5770
Epoch 3/200: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 94/94 [01:50<00:00,  1.18s/it, loss=0.0898]
Epoch 3/200, Train Loss: 0.0898, Train_acc: 0.7546, Val Loss: 0.9053, Val_acc: 0.6147
Epoch 4/200: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 94/94 [01:51<00:00,  1.19s/it, loss=0.0762]
Epoch 4/200, Train Loss: 0.0762, Train_acc: 0.8459, Val Loss: 0.8928, Val_acc: 0.6055
Epoch 5/200:  30%|███████████████████████████████████████▌                                                                                             | 28/94 [00:34<01:22,  1.25s/it, loss=0.0682]
Traceback (most recent call last):
  File "/home/yunkwan/project/radarclip/distillation.py", line 391, in <module>
    main(args.train_3, args.epochs, args.batch_size, args.test_mode)
  File "/home/yunkwan/project/radarclip/distillation.py", line 376, in main
    train_model(teacher_model, student_model, retrieval_model,train_loader, val_loader, criterion, optimizer, warmup_scheduler, cosine_scheduler, prepro_image_fn=prepro_image_features, num_epochs=num_epochs, filter=LearnableLogFilter_3)
  File "/home/yunkwan/project/radarclip/distillation.py", line 175, in train_model
    for images, radars, _, _, labels in train_loader_tqdm:
  File "/home/yunkwan/anaconda3/envs/smallcap/lib/python3.9/site-packages/tqdm/std.py", line 1195, in __iter__
    for obj in iterable:
  File "/home/yunkwan/anaconda3/envs/smallcap/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 631, in __next__
    data = self._next_data()
  File "/home/yunkwan/anaconda3/envs/smallcap/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 675, in _next_data
    data = self._dataset_fetcher.fetch(index)  # may raise StopIteration
  File "/home/yunkwan/anaconda3/envs/smallcap/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py", line 51, in fetch
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/home/yunkwan/anaconda3/envs/smallcap/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py", line 51, in <listcomp>
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/home/yunkwan/project/radarclip/dataload.py", line 108, in __getitem__
    image = self.transform(image)
  File "/home/yunkwan/anaconda3/envs/smallcap/lib/python3.9/site-packages/torchvision/transforms/transforms.py", line 95, in __call__
    img = t(img)
  File "/home/yunkwan/anaconda3/envs/smallcap/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/yunkwan/anaconda3/envs/smallcap/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1541, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/yunkwan/anaconda3/envs/smallcap/lib/python3.9/site-packages/torchvision/transforms/transforms.py", line 354, in forward
    return F.resize(img, self.size, self.interpolation, self.max_size, self.antialias)
  File "/home/yunkwan/anaconda3/envs/smallcap/lib/python3.9/site-packages/torchvision/transforms/functional.py", line 456, in resize
    _, image_height, image_width = get_dimensions(img)
  File "/home/yunkwan/anaconda3/envs/smallcap/lib/python3.9/site-packages/torchvision/transforms/functional.py", line 78, in get_dimensions
    return F_t.get_dimensions(img)
  File "/home/yunkwan/anaconda3/envs/smallcap/lib/python3.9/site-packages/torchvision/transforms/_functional_tensor.py", line 19, in get_dimensions
    _assert_image_tensor(img)
KeyboardInterrupt
