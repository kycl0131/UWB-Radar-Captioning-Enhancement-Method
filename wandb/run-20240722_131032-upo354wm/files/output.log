Some weights of SmallCap were not initialized from the model checkpoint at Yova/SmallCap7M and are newly initialized: ['encoder_radar.layer3.6.bn2.weight', 'encoder_radar.layer3.16.bn3.num_batches_tracked', 'encoder_radar.layer1.2.bn1.bias', 'encoder_radar.layer2.3.bn3.weight', 'encoder_radar.layer1.2.bn2.running_mean', 'encoder_radar.layer3.7.bn3.running_mean', 'encoder_radar.layer3.10.bn3.bias', 'encoder_radar.layer3.2.bn3.running_var', 'encoder_radar.layer3.15.bn3.running_var', 'encoder_radar.layer4.0.bn1.weight', 'encoder_radar.layer1.1.bn2.running_mean', 'encoder_radar.layer4.1.bn2.weight', 'encoder_radar.layer3.10.conv3.weight', 'encoder_radar.layer3.14.bn1.weight', 'encoder_radar.layer3.16.bn1.running_mean', 'encoder_radar.layer3.12.bn1.running_mean', 'encoder_radar.layer3.8.bn1.weight', 'encoder_radar.layer3.0.bn3.running_var', 'encoder_radar.layer2.0.bn2.weight', 'encoder_radar.layer4.2.bn1.running_mean', 'encoder_radar.layer3.18.bn3.running_mean', 'encoder_radar.layer3.5.bn3.bias', 'encoder_radar.layer4.1.bn2.running_mean', 'encoder_radar.layer3.12.bn2.running_var', 'encoder_radar.layer3.15.bn1.running_mean', 'encoder_radar.layer4.0.bn2.num_batches_tracked', 'encoder_radar.layer3.3.bn2.running_var', 'encoder_radar.layer3.20.bn1.bias', 'encoder_radar.layer1.2.conv2.weight', 'encoder_radar.layer3.12.bn3.running_mean', 'encoder_radar.layer2.1.bn2.num_batches_tracked', 'encoder_radar.layer2.1.conv3.weight', 'encoder_radar.layer2.3.bn1.num_batches_tracked', 'encoder_radar.layer4.1.bn1.num_batches_tracked', 'encoder_radar.layer4.0.bn2.running_var', 'encoder_radar.layer3.17.bn3.running_mean', 'encoder_radar.layer3.12.conv3.weight', 'encoder_radar.layer3.14.bn1.running_mean', 'encoder_radar.layer3.12.conv1.weight', 'encoder_radar.layer3.7.bn1.bias', 'encoder_radar.layer3.21.bn2.running_mean', 'encoder_radar.layer3.11.bn1.bias', 'encoder_radar.layer3.11.bn3.running_var', 'encoder_radar.layer3.14.conv1.weight', 'encoder_radar.layer2.0.bn3.running_mean', 'encoder_radar.layer3.6.bn1.num_batches_tracked', 'encoder_radar.layer3.4.bn3.running_mean', 'encoder_radar.layer2.1.bn3.num_batches_tracked', 'encoder_radar.layer2.0.bn1.running_mean', 'encoder_radar.layer3.10.conv2.weight', 'encoder_radar.layer1.0.bn3.num_batches_tracked', 'encoder_radar.layer3.4.conv2.weight', 'encoder_radar.layer3.19.bn3.running_mean', 'encoder_radar.layer3.20.bn3.running_var', 'encoder_radar.layer4.2.bn1.bias', 'encoder_radar.layer1.0.bn1.num_batches_tracked', 'encoder_radar.layer1.0.bn2.bias', 'encoder_radar.layer3.8.bn3.num_batches_tracked', 'encoder_radar.layer1.1.bn2.bias', 'encoder_radar.layer3.5.bn2.bias', 'encoder_radar.layer3.18.bn3.weight', 'encoder_radar.layer4.2.bn2.num_batches_tracked', 'encoder_radar.layer3.5.bn1.running_var', 'encoder_radar.layer2.2.bn1.running_mean', 'encoder_radar.layer4.2.conv1.weight', 'encoder_radar.layer2.1.bn2.weight', 'encoder_radar.layer3.4.bn1.num_batches_tracked', 'encoder_radar.layer3.3.bn1.weight', 'encoder_radar.layer1.1.bn1.weight', 'encoder_radar.layer4.2.conv2.weight', 'encoder_radar.layer3.16.bn3.running_mean', 'encoder_radar.layer3.16.bn3.running_var', 'encoder_radar.layer3.22.bn1.running_var', 'encoder_radar.layer3.20.bn3.bias', 'encoder_radar.layer1.2.bn3.bias', 'encoder_radar.layer3.22.bn3.weight', 'encoder_radar.layer3.1.bn1.num_batches_tracked', 'encoder_radar.layer3.22.bn1.weight', 'encoder_radar.layer3.10.bn1.num_batches_tracked', 'encoder_radar.layer3.10.bn1.running_mean', 'encoder_radar.layer3.19.bn1.bias', 'encoder_radar.layer3.3.bn1.running_mean', 'encoder_radar.layer1.2.bn3.running_var', 'encoder_radar.layer3.2.bn2.bias', 'encoder_radar.layer2.0.bn2.bias', 'encoder_radar.layer2.3.bn1.running_var', 'encoder_radar.layer3.19.bn2.bias', 'encoder_radar.layer2.1.bn2.running_var', 'encoder_radar.layer3.8.bn2.weight', 'encoder_radar.layer3.4.bn3.running_var', 'encoder_radar.layer3.19.bn2.num_batches_tracked', 'encoder_radar.layer3.15.conv3.weight', 'encoder_radar.layer4.0.bn3.weight', 'encoder_radar.layer2.2.bn2.weight', 'encoder_radar.layer3.9.bn1.bias', 'encoder_radar.layer3.5.bn2.num_batches_tr
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Epoch 1/30: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████| 94/94 [01:33<00:00,  1.00it/s, loss=0.834]
Epoch 1/30, Train Loss: 0.8342, Train_acc: 0.6036, Val Loss: 1.1707 , Val_acc: 0.5407
Epoch 2/30: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████| 94/94 [01:31<00:00,  1.03it/s, loss=0.463]
Epoch 2/30, Train Loss: 0.4633, Train_acc: 0.8204, Val Loss: 1.2812 , Val_acc: 0.6188
Epoch 3/30: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████| 94/94 [01:31<00:00,  1.02it/s, loss=0.352]
Epoch 3/30, Train Loss: 0.3520, Train_acc: 0.8667, Val Loss: 1.1255 , Val_acc: 0.6638
Epoch 4/30: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████| 94/94 [01:33<00:00,  1.01it/s, loss=0.275]
Epoch 4/30, Train Loss: 0.2754, Train_acc: 0.8966, Val Loss: 1.1619 , Val_acc: 0.6962
Epoch 5/30: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████| 94/94 [01:31<00:00,  1.02it/s, loss=0.232]
Epoch 5/30, Train Loss: 0.2318, Train_acc: 0.9130, Val Loss: 1.0049 , Val_acc: 0.7142
Epoch 6/30: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████| 94/94 [01:34<00:00,  1.01s/it, loss=0.198]
Epoch 6/30, Train Loss: 0.1982, Train_acc: 0.9270, Val Loss: 1.2394 , Val_acc: 0.7165
Epoch 7/30: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████| 94/94 [01:32<00:00,  1.01it/s, loss=0.145]
Epoch 7/30, Train Loss: 0.1455, Train_acc: 0.9480, Val Loss: 1.1424 , Val_acc: 0.7255
Epoch 8/30: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████| 94/94 [01:33<00:00,  1.01it/s, loss=0.131]
Epoch 8/30, Train Loss: 0.1314, Train_acc: 0.9524, Val Loss: 1.2667 , Val_acc: 0.6948
Epoch 9/30: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████| 94/94 [01:33<00:00,  1.00it/s, loss=0.104]
Epoch 9/30, Train Loss: 0.1038, Train_acc: 0.9630, Val Loss: 1.2360 , Val_acc: 0.7250
Epoch 10/30: 100%|████████████████████████████████████████████████████████████████████████████████████████████████| 94/94 [01:32<00:00,  1.01it/s, loss=0.0812]
Epoch 10/30, Train Loss: 0.0812, Train_acc: 0.9703, Val Loss: 1.3345 , Val_acc: 0.7177
Epoch 11/30: 100%|████████████████████████████████████████████████████████████████████████████████████████████████| 94/94 [01:31<00:00,  1.02it/s, loss=0.0776]
Epoch 11/30, Train Loss: 0.0776, Train_acc: 0.9712, Val Loss: 1.1826 , Val_acc: 0.7172
Epoch 12/30: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████| 94/94 [01:31<00:00,  1.02it/s, loss=0.06]
Epoch 12/30, Train Loss: 0.0600, Train_acc: 0.9786, Val Loss: 1.2876 , Val_acc: 0.7393
Epoch 13/30: 100%|████████████████████████████████████████████████████████████████████████████████████████████████| 94/94 [01:32<00:00,  1.01it/s, loss=0.0508]
Epoch 13/30, Train Loss: 0.0508, Train_acc: 0.9822, Val Loss: 1.3041 , Val_acc: 0.7445
Epoch 14/30: 100%|████████████████████████████████████████████████████████████████████████████████████████████████| 94/94 [01:33<00:00,  1.00it/s, loss=0.0473]
Epoch 14/30, Train Loss: 0.0473, Train_acc: 0.9840, Val Loss: 1.4630 , Val_acc: 0.7397
Epoch 15/30: 100%|████████████████████████████████████████████████████████████████████████████████████████████████| 94/94 [01:32<00:00,  1.02it/s, loss=0.0485]
Epoch 15/30, Train Loss: 0.0485, Train_acc: 0.9832, Val Loss: 1.6747 , Val_acc: 0.7125
Epoch 16/30: 100%|████████████████████████████████████████████████████████████████████████████████████████████████| 94/94 [01:33<00:00,  1.01it/s, loss=0.0418]
Epoch 16/30, Train Loss: 0.0418, Train_acc: 0.9850, Val Loss: 1.3992 , Val_acc: 0.7412
Epoch 17/30: 100%|████████████████████████████████████████████████████████████████████████████████████████████████| 94/94 [01:32<00:00,  1.02it/s, loss=0.0355]
Epoch 17/30, Train Loss: 0.0355, Train_acc: 0.9875, Val Loss: 1.3774 , Val_acc: 0.7418
Epoch 18/30: 100%|████████████████████████████████████████████████████████████████████████████████████████████████| 94/94 [01:33<00:00,  1.01it/s, loss=0.0416]
Epoch 18/30, Train Loss: 0.0416, Train_acc: 0.9849, Val Loss: 1.5095 , Val_acc: 0.7305
Epoch 19/30:  13%|████████████▎                                                                                   | 12/94 [00:12<01:24,  1.03s/it, loss=0.0423]
Traceback (most recent call last):
  File "/home/yunkwan/project/radarclip/Radarcap_main_cl.py", line 550, in <module>
  File "/home/yunkwan/project/radarclip/Radarcap_main_cl.py", line 535, in main
  File "/home/yunkwan/project/radarclip/Radarcap_main_cl.py", line 263, in train_model
    # pdb.set_trace()
  File "/home/yunkwan/anaconda3/envs/smallcap/lib/python3.9/site-packages/tqdm/std.py", line 1195, in __iter__
    for obj in iterable:
  File "/home/yunkwan/anaconda3/envs/smallcap/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 631, in __next__
    data = self._next_data()
  File "/home/yunkwan/anaconda3/envs/smallcap/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 675, in _next_data
    data = self._dataset_fetcher.fetch(index)  # may raise StopIteration
  File "/home/yunkwan/anaconda3/envs/smallcap/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py", line 51, in fetch
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/home/yunkwan/anaconda3/envs/smallcap/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py", line 51, in <listcomp>
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/home/yunkwan/project/radarclip/dataload.py", line 108, in __getitem__
    image = self.transform(image)
  File "/home/yunkwan/anaconda3/envs/smallcap/lib/python3.9/site-packages/torchvision/transforms/transforms.py", line 95, in __call__
    img = t(img)
  File "/home/yunkwan/project/radarclip/Radarcap_main_cl.py", line 69, in __call__
    img = Image.fromarray(img)
  File "/home/yunkwan/anaconda3/envs/smallcap/lib/python3.9/site-packages/PIL/Image.py", line 3154, in fromarray
    return frombuffer(mode, size, obj, "raw", rawmode, 0, 1)
  File "/home/yunkwan/anaconda3/envs/smallcap/lib/python3.9/site-packages/PIL/Image.py", line 3069, in frombuffer
    return frombytes(mode, size, data, decoder_name, args)
  File "/home/yunkwan/anaconda3/envs/smallcap/lib/python3.9/site-packages/PIL/Image.py", line 3012, in frombytes
    im.frombytes(data, decoder_name, args)
  File "/home/yunkwan/anaconda3/envs/smallcap/lib/python3.9/site-packages/PIL/Image.py", line 826, in frombytes
    s = d.decode(data)
KeyboardInterrupt
