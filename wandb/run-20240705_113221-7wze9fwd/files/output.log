Epoch 1/10:   0%|                                                                                                                                                                                                   | 0/341 [00:00<?, ?it/s]
torch.Size([32, 600, 600])
Traceback (most recent call last):
  File "/home/yunkwan/project/radarclip/Radarcap_main.py", line 407, in <module>
    main(args.train_1024, args.train_768, args.epochs, args.batch_size)
  File "/home/yunkwan/project/radarclip/Radarcap_main.py", line 355, in main
    train_model(encoder_search_resnet1D_1024, retrieval_model, train_loader, val_loader, criterion, optimizer, prepro_image_features_1024, num_epochs=num_epochs,filter = LearnableLogFilter_1024)
  File "/home/yunkwan/project/radarclip/Radarcap_main.py", line 231, in train_model
    swvds =swvds.permute(0, 3, 2, 1)
RuntimeError: permute(sparse_coo): number of dimensions in the tensor input does not match the length of the desired ordering of dimensions i.e. input.dim() = 3 is not equal to len(dims) = 4
