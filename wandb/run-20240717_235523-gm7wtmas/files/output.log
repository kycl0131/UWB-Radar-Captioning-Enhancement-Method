Some weights of SmallCap were not initialized from the model checkpoint at Yova/SmallCap7M and are newly initialized: ['encoder_radar.layer3.15.bn1.num_batches_tracked', 'encoder_radar.layer3.3.bn1.running_var', 'encoder_radar.layer4.0.conv1.weight', 'encoder_radar.layer3.1.bn3.num_batches_tracked', 'encoder_radar.layer3.14.bn1.running_var', 'encoder_radar.layer3.17.bn2.running_mean', 'encoder_radar.layer3.5.bn3.bias', 'encoder_radar.layer1.1.bn2.num_batches_tracked', 'encoder_radar.layer3.8.bn2.num_batches_tracked', 'encoder_radar.layer3.4.conv3.weight', 'encoder_radar.layer3.10.bn2.num_batches_tracked', 'encoder_radar.layer3.20.bn1.num_batches_tracked', 'encoder_radar.layer3.10.bn3.num_batches_tracked', 'encoder_radar.layer3.6.conv3.weight', 'encoder_radar.layer3.7.bn3.num_batches_tracked', 'encoder_radar.layer3.0.bn2.num_batches_tracked', 'encoder_radar.layer2.1.bn3.weight', 'encoder_radar.layer3.15.bn3.bias', 'encoder_radar.layer3.5.bn3.weight', 'encoder_radar.layer2.0.bn3.bias', 'encoder_radar.layer3.21.bn2.bias', 'encoder_radar.layer2.1.bn1.bias', 'encoder_radar.layer3.19.bn3.running_var', 'encoder_radar.layer2.2.bn3.num_batches_tracked', 'encoder_radar.layer4.2.bn3.weight', 'encoder_radar.layer1.1.conv2.weight', 'encoder_radar.layer3.14.bn2.bias', 'encoder_radar.layer2.3.conv1.weight', 'encoder_radar.layer3.21.bn3.running_mean', 'encoder_radar.layer4.0.downsample.1.num_batches_tracked', 'encoder_radar.layer3.18.bn1.bias', 'encoder_radar.layer3.3.bn3.bias', 'encoder_radar.layer3.16.conv3.weight', 'encoder_radar.layer3.20.bn3.num_batches_tracked', 'encoder_radar.layer1.0.bn3.bias', 'encoder_radar.layer4.0.bn1.num_batches_tracked', 'encoder_radar.layer3.9.conv2.weight', 'encoder_radar.layer2.2.bn1.running_var', 'encoder_radar.layer2.2.bn2.bias', 'encoder_radar.layer3.0.bn1.num_batches_tracked', 'encoder_radar.layer3.15.bn2.running_mean', 'encoder_radar.layer3.17.conv1.weight', 'encoder_radar.layer3.5.bn2.weight', 'encoder_radar.layer1.0.bn2.running_var', 'encoder_radar.layer4.2.conv2.weight', 'encoder_radar.layer3.9.bn1.weight', 'encoder_radar.layer3.20.bn2.running_var', 'encoder_radar.layer3.17.conv3.weight', 'encoder_radar.layer4.0.bn3.running_var', 'encoder_radar.layer1.1.bn3.running_mean', 'encoder_radar.layer1.2.conv2.weight', 'encoder_radar.layer3.0.bn2.running_mean', 'encoder_radar.layer3.21.bn1.weight', 'encoder_radar.layer3.4.bn2.running_mean', 'encoder_radar.layer2.2.bn1.num_batches_tracked', 'encoder_radar.layer3.2.bn2.running_var', 'encoder_radar.layer2.0.conv1.weight', 'encoder_radar.layer3.8.bn3.weight', 'encoder_radar.layer3.13.conv1.weight', 'encoder_radar.layer3.18.conv3.weight', 'encoder_radar.layer3.9.bn1.running_var', 'encoder_radar.layer3.7.bn2.bias', 'encoder_radar.layer4.2.bn1.running_var', 'encoder_radar.layer3.9.bn3.running_var', 'encoder_radar.layer3.16.bn3.bias', 'encoder_radar.layer3.14.conv2.weight', 'encoder_radar.layer3.10.bn3.running_mean', 'encoder_radar.layer1.0.downsample.1.running_mean', 'encoder_radar.layer3.14.bn2.running_mean', 'encoder_radar.layer3.20.bn1.bias', 'encoder_radar.layer3.7.bn3.running_mean', 'encoder_radar.layer3.16.bn3.weight', 'encoder_radar.layer4.1.bn1.num_batches_tracked', 'encoder_radar.layer1.1.bn1.bias', 'encoder_radar.layer2.0.downsample.1.num_batches_tracked', 'encoder_radar.layer1.0.downsample.1.num_batches_tracked', 'encoder_radar.layer3.0.bn1.weight', 'encoder_radar.layer3.13.bn3.num_batches_tracked', 'encoder_radar.layer3.2.conv2.weight', 'encoder_radar.layer3.5.bn3.running_var', 'encoder_radar.layer4.2.bn3.bias', 'encoder_radar.layer3.7.bn3.weight', 'encoder_radar.layer3.5.bn2.running_mean', 'encoder_radar.layer3.12.bn3.running_mean', 'encoder_radar.layer3.2.bn1.num_batches_tracked', 'encoder_radar.layer3.4.bn2.bias', 'encoder_radar.layer2.2.bn2.running_mean', 'encoder_radar.layer3.8.bn1.bias', 'encoder_radar.layer2.1.conv3.weight', 'encoder_radar.layer3.11.bn1.running_var', 'encoder_radar.layer3.22.bn3.bias', 'encoder_radar.layer4.1.bn3.weight', 'encoder_radar.layer4.1.bn1.running_var', 'encoder_radar.layer1.1.bn1.weight', 'encoder_radar.layer2.3.co
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Epoch 1/30: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 94/94 [02:01<00:00,  1.29s/it, loss=0.322]
Epoch 1/30, Train Loss: 0.3216, Train_acc: 0.4190, Val Loss: 1.1264, Val_acc: 0.3338
Epoch 2/30: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 94/94 [01:56<00:00,  1.24s/it, loss=0.277]
Epoch 2/30, Train Loss: 0.2772, Train_acc: 0.6397, Val Loss: 0.8561, Val_acc: 0.6387
Epoch 3/30: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 94/94 [02:03<00:00,  1.32s/it, loss=0.226]
Epoch 3/30, Train Loss: 0.2257, Train_acc: 0.7636, Val Loss: 0.7685, Val_acc: 0.6830
Epoch 4/30: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 94/94 [02:02<00:00,  1.30s/it, loss=0.18]
Epoch 4/30, Train Loss: 0.1802, Train_acc: 0.8335, Val Loss: 0.7155, Val_acc: 0.7207
Epoch 5/30: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 94/94 [02:00<00:00,  1.29s/it, loss=0.155]
Epoch 5/30, Train Loss: 0.1547, Train_acc: 0.8644, Val Loss: 0.7508, Val_acc: 0.7197
Epoch 6/30: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 94/94 [02:01<00:00,  1.29s/it, loss=0.142]
Epoch 6/30, Train Loss: 0.1423, Train_acc: 0.8815, Val Loss: 0.6954, Val_acc: 0.7292
Epoch 7/30: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 94/94 [02:04<00:00,  1.32s/it, loss=0.132]
Epoch 7/30, Train Loss: 0.1322, Train_acc: 0.8951, Val Loss: 0.7570, Val_acc: 0.7062
Epoch 8/30: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 94/94 [01:59<00:00,  1.28s/it, loss=0.123]
Epoch 8/30, Train Loss: 0.1233, Train_acc: 0.9080, Val Loss: 0.6932, Val_acc: 0.7410
Epoch 9/30: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 94/94 [01:59<00:00,  1.27s/it, loss=0.121]
Epoch 9/30, Train Loss: 0.1211, Train_acc: 0.9127, Val Loss: 0.7327, Val_acc: 0.7323
Epoch 10/30: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 94/94 [01:58<00:00,  1.26s/it, loss=0.118]
Epoch 10/30, Train Loss: 0.1178, Train_acc: 0.9170, Val Loss: 0.7474, Val_acc: 0.7200
Epoch 11/30: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 94/94 [01:57<00:00,  1.25s/it, loss=0.112]
Epoch 11/30, Train Loss: 0.1124, Train_acc: 0.9263, Val Loss: 0.7072, Val_acc: 0.7373
Epoch 12/30: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 94/94 [02:00<00:00,  1.28s/it, loss=0.109]
[34m[1mwandb[0m: Ctrl + C detected. Stopping sweep.
